{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MLP for Regression and Classificaiton using both PyTorch and Tensorflow"
      ],
      "metadata": {
        "id": "DFq2aBGJ3eZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 0: Set Up the Environment\n",
        "Ensure you have PySpark, PyTorch, and other necessary libraries installed."
      ],
      "metadata": {
        "id": "4W0UFgQz3l9K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "x2jK-moc3dMC"
      },
      "outputs": [],
      "source": [
        "# ! pip install pyspark torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing, load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow import keras\n",
        "from keras import layers, Input\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "tiVmq72dUMG-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: MLP for Regression – Predicting California Housing Prices\n",
        "\n"
      ],
      "metadata": {
        "id": "SeVRwwV04gSP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Load and Prepare the Data\n",
        "* Load the California housing dataset into a Pandas DataFrame.\n",
        "* Convert it into a Spark DataFrame for distributed processing.\n",
        "* Assemble feature vectors for PySpark."
      ],
      "metadata": {
        "id": "13jZ3NWm3iq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and Normalize California Housing Data\n",
        "housing = fetch_california_housing()\n",
        "df_housing = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
        "df_housing['target'] = housing.target  # Apply log transformation\n",
        "\n",
        "X = df_housing[housing.feature_names].values\n",
        "y = df_housing['target'].values\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "oHTz8PN83vOi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: [PyTorch] Convert Spark Data to PyTorch Tensors"
      ],
      "metadata": {
        "id": "lXoORM4A3wlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert NumPy arrays to PyTorch tensors\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_t = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n"
      ],
      "metadata": {
        "id": "_cGg8VbJ4z7H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: [PyTorch] Build the MLP Model for Regression"
      ],
      "metadata": {
        "id": "hI-uZHPj48m6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define MLP architecture to match TensorFlow\n",
        "class MLPRegressor(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(MLPRegressor, self).__init__()\n",
        "        # First layer with BatchNorm\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Linear(input_size, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        # Second layer with ReLU and then Dropout (matching TensorFlow placement)\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3)  # Moved dropout after ReLU to match TensorFlow\n",
        "        )\n",
        "        # Output layer\n",
        "        self.layer3 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        return x\n",
        "\n",
        "# Create model\n",
        "pt_model_regression = MLPRegressor(X_train.shape[1])\n",
        "\n",
        "# Use Adam optimizer with default settings to match TensorFlow\n",
        "# TensorFlow default Adam: lr=0.001, beta1=0.9, beta2=0.999, epsilon=1e-7\n",
        "optimizer = optim.Adam(\n",
        "    pt_model_regression.parameters(),\n",
        "    lr=0.001,  # Default TensorFlow learning rate\n",
        "    betas=(0.9, 0.999),  # Default betas\n",
        "    eps=1e-8  # PyTorch default epsilon (slightly different from TF)\n",
        ")\n"
      ],
      "metadata": {
        "id": "0MPNiQx55D0U"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: [PyTorch] Train the Regression Model"
      ],
      "metadata": {
        "id": "w5l1N6rY5F6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Create DataLoader for mini-batch training\n",
        "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # Match TF batch size=32\n",
        "\n",
        "# Training loop with mini-batches (50 epochs to match TensorFlow)\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Mini-batch training\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = pt_model_regression(batch_x)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Print statistics (similar to TensorFlow verbose=1)\n",
        "    if epoch % 10 == 0 or epoch == num_epochs-1:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkHJcyrO5Jk-",
        "outputId": "f4c230ee-5be3-4c27-b257-fb05c047364a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Loss: 1.0470\n",
            "Epoch [11/50], Loss: 0.4322\n",
            "Epoch [21/50], Loss: 0.3952\n",
            "Epoch [31/50], Loss: 0.3819\n",
            "Epoch [41/50], Loss: 0.3762\n",
            "Epoch [50/50], Loss: 0.3726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: [PyTorch] Evaluate the Regression Model"
      ],
      "metadata": {
        "id": "ASWz5pn_5LzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "pt_model_regression.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = pt_model_regression(X_test_t)\n",
        "    mse_loss = criterion(predictions, y_test_t)\n",
        "    mae_loss = nn.L1Loss()(predictions, y_test_t)  # Calculate MAE to match TensorFlow metrics\n",
        "\n",
        "print(f'Test Mean Squared Error: {mse_loss.item():.4f}')\n",
        "print(f'Test Mean Absolute Error: {mae_loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2mKp1dp5lTZ",
        "outputId": "658889e6-ad86-4465-a908-c717178dcab0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Mean Squared Error: 0.3007\n",
            "Test Mean Absolute Error: 0.3702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6: [PyTorch] Make Predictions with the Regression Model"
      ],
      "metadata": {
        "id": "z6b_D0Tf5oyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with scaled input (matching TensorFlow's approach)\n",
        "sample_input_np = np.array([[8.0, 41.0, 6.0, 1.0, 950.0, 4.0, 37.0, -122.0]])\n",
        "sample_input_scaled = scaler.transform(sample_input_np)  # Apply scaling\n",
        "sample_input_t = torch.tensor(sample_input_scaled, dtype=torch.float32)\n",
        "\n",
        "pt_model_regression.eval()\n",
        "with torch.no_grad():\n",
        "    pt_prediction = pt_model_regression(sample_input_t).item()\n",
        "\n",
        "print(f'Predicted House Price: {pt_prediction:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZBlDiRG5rlN",
        "outputId": "57f9301e-733e-40b0-faba-198528de01fe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted House Price: 3.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7: [TensorFlow] Build the MLP Model for Regression"
      ],
      "metadata": {
        "id": "Izc9GcLd6_D-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define MLP architecture\n",
        "tf_model_regression = keras.Sequential([\n",
        "    layers.Dense(64, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(32, activation=\"relu\"),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "tf_model_regression.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# Display model summary\n",
        "tf_model_regression.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "-MmwmfrC7BXN",
        "outputId": "52bbf81e-4acc-47fc-f277-b8254e454b93"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m576\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,945\u001b[0m (11.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,945</span> (11.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,817\u001b[0m (11.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,817</span> (11.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 8: [TensorFlow] Train the Regression Model"
      ],
      "metadata": {
        "id": "hBnx133N7IbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "tf_history_regression = tf_model_regression.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WSzTOKnx7OoX",
        "outputId": "f89a089b-d09b-412b-d508-51f6ea7ab164"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 1.7180 - mae: 0.9643 - val_loss: 0.6702 - val_mae: 0.5625\n",
            "Epoch 2/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.6745 - mae: 0.6051 - val_loss: 0.5024 - val_mae: 0.4865\n",
            "Epoch 3/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5547 - mae: 0.5429 - val_loss: 0.4323 - val_mae: 0.4492\n",
            "Epoch 4/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.5075 - mae: 0.5134 - val_loss: 0.3821 - val_mae: 0.4197\n",
            "Epoch 5/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4626 - mae: 0.4856 - val_loss: 0.3714 - val_mae: 0.4118\n",
            "Epoch 6/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.4452 - mae: 0.4765 - val_loss: 0.3500 - val_mae: 0.4075\n",
            "Epoch 7/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4282 - mae: 0.4661 - val_loss: 0.3544 - val_mae: 0.4150\n",
            "Epoch 8/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4188 - mae: 0.4645 - val_loss: 0.3452 - val_mae: 0.4027\n",
            "Epoch 9/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4084 - mae: 0.4578 - val_loss: 0.3794 - val_mae: 0.4268\n",
            "Epoch 10/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4059 - mae: 0.4540 - val_loss: 0.3400 - val_mae: 0.4048\n",
            "Epoch 11/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.3932 - mae: 0.4463 - val_loss: 0.3511 - val_mae: 0.4173\n",
            "Epoch 12/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3820 - mae: 0.4426 - val_loss: 0.3349 - val_mae: 0.4073\n",
            "Epoch 13/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3927 - mae: 0.4477 - val_loss: 0.3425 - val_mae: 0.4055\n",
            "Epoch 14/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3931 - mae: 0.4418 - val_loss: 0.3519 - val_mae: 0.4070\n",
            "Epoch 15/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.3775 - mae: 0.4382 - val_loss: 0.3681 - val_mae: 0.4329\n",
            "Epoch 16/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3647 - mae: 0.4313 - val_loss: 0.3408 - val_mae: 0.4118\n",
            "Epoch 17/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3943 - mae: 0.4458 - val_loss: 0.3993 - val_mae: 0.4592\n",
            "Epoch 18/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3656 - mae: 0.4327 - val_loss: 0.3385 - val_mae: 0.4200\n",
            "Epoch 19/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.3658 - mae: 0.4325 - val_loss: 0.3427 - val_mae: 0.4129\n",
            "Epoch 20/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3717 - mae: 0.4351 - val_loss: 0.3809 - val_mae: 0.4501\n",
            "Epoch 21/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3703 - mae: 0.4328 - val_loss: 0.3318 - val_mae: 0.3978\n",
            "Epoch 22/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.3705 - mae: 0.4306 - val_loss: 0.3501 - val_mae: 0.4283\n",
            "Epoch 23/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.3649 - mae: 0.4266 - val_loss: 0.3281 - val_mae: 0.4005\n",
            "Epoch 24/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3642 - mae: 0.4292 - val_loss: 0.3498 - val_mae: 0.4340\n",
            "Epoch 25/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3522 - mae: 0.4192 - val_loss: 0.3219 - val_mae: 0.4062\n",
            "Epoch 26/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3544 - mae: 0.4245 - val_loss: 0.3453 - val_mae: 0.4196\n",
            "Epoch 27/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.3463 - mae: 0.4198 - val_loss: 0.3386 - val_mae: 0.4115\n",
            "Epoch 28/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3663 - mae: 0.4318 - val_loss: 0.3411 - val_mae: 0.4099\n",
            "Epoch 29/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3461 - mae: 0.4173 - val_loss: 0.3422 - val_mae: 0.4133\n",
            "Epoch 30/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.3471 - mae: 0.4215 - val_loss: 0.3330 - val_mae: 0.4170\n",
            "Epoch 31/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3503 - mae: 0.4227 - val_loss: 0.3436 - val_mae: 0.4137\n",
            "Epoch 32/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3369 - mae: 0.4149 - val_loss: 0.3445 - val_mae: 0.4233\n",
            "Epoch 33/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3361 - mae: 0.4162 - val_loss: 0.3199 - val_mae: 0.3992\n",
            "Epoch 34/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3477 - mae: 0.4194 - val_loss: 0.3332 - val_mae: 0.4062\n",
            "Epoch 35/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.3438 - mae: 0.4177 - val_loss: 0.2990 - val_mae: 0.3792\n",
            "Epoch 36/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3575 - mae: 0.4224 - val_loss: 0.3058 - val_mae: 0.3870\n",
            "Epoch 37/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3402 - mae: 0.4184 - val_loss: 0.3462 - val_mae: 0.4193\n",
            "Epoch 38/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3413 - mae: 0.4169 - val_loss: 0.3539 - val_mae: 0.4160\n",
            "Epoch 39/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3332 - mae: 0.4133 - val_loss: 0.3103 - val_mae: 0.3849\n",
            "Epoch 40/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3336 - mae: 0.4115 - val_loss: 0.3312 - val_mae: 0.4148\n",
            "Epoch 41/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3380 - mae: 0.4148 - val_loss: 0.3212 - val_mae: 0.4073\n",
            "Epoch 42/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.3329 - mae: 0.4120 - val_loss: 0.3185 - val_mae: 0.4054\n",
            "Epoch 43/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3402 - mae: 0.4151 - val_loss: 0.3231 - val_mae: 0.4180\n",
            "Epoch 44/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3231 - mae: 0.4068 - val_loss: 0.3282 - val_mae: 0.4201\n",
            "Epoch 45/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3596 - mae: 0.4266 - val_loss: 0.3322 - val_mae: 0.4080\n",
            "Epoch 46/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3462 - mae: 0.4174 - val_loss: 0.2983 - val_mae: 0.3815\n",
            "Epoch 47/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3313 - mae: 0.4076 - val_loss: 0.3259 - val_mae: 0.4117\n",
            "Epoch 48/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3216 - mae: 0.4056 - val_loss: 0.3013 - val_mae: 0.3804\n",
            "Epoch 49/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3271 - mae: 0.4100 - val_loss: 0.3166 - val_mae: 0.4082\n",
            "Epoch 50/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3308 - mae: 0.4081 - val_loss: 0.3167 - val_mae: 0.4048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 9: [TensorFlow] Evaluate the Regression Model"
      ],
      "metadata": {
        "id": "OFOnyOGV7PU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "loss, mae = tf_model_regression.evaluate(X_test, y_test)\n",
        "print(f\"Test Mean Absolute Error: {mae:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaiR3tuf7S5h",
        "outputId": "591aeabb-10ed-4349-fc8a-7b68244d4e5d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3080 - mae: 0.4020\n",
            "Test Mean Absolute Error: 0.4048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 10:[TensorFlow] Make Predictions with the Regression Model"
      ],
      "metadata": {
        "id": "puK16Lpi7Ua8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample input for prediction\n",
        "sample_input = np.array([[8.0, 41.0, 6.0, 1.0, 950.0, 4.0, 37.0, -122.0]])\n",
        "sample_input = scaler.transform(sample_input)  # Apply same scaling\n",
        "\n",
        "# Make prediction\n",
        "predicted_price = tf_model_regression.predict(sample_input)[0, 0]\n",
        "print(f\"Predicted House Price: {predicted_price:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUkiJibE7ae5",
        "outputId": "775cd5b0-ee8a-4f59-9ae2-120c4606b06d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n",
            "Predicted House Price: 3.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: MLP for Classification – Predicting Iris Flower Species"
      ],
      "metadata": {
        "id": "XGT_gcbwjO1p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 11: Load and Prepare the Data\n",
        "* Load the Iris dataset into a Pandas DataFrame.\n",
        "* Convert it into a Spark DataFrame.\n",
        "* Encode categorical labels and assemble features."
      ],
      "metadata": {
        "id": "rpmSIlTOjPcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "iris = load_iris()\n",
        "df_iris = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df_iris['label'] = iris.target\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "X = df_iris[iris.feature_names].values\n",
        "y = df_iris['label'].values\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "kvmpZTIdjWjZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 12: (PyTorch) Convert Spark Data to PyTorch Tensors"
      ],
      "metadata": {
        "id": "Z99ffMINjYT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to PyTorch tensors\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.long)  # Long tensor for classification\n",
        "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_t = torch.tensor(y_test, dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "jlc8YIovje7d"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 13: (PyTorch) Build the MLP Model for Classification"
      ],
      "metadata": {
        "id": "Ydzx9We9jhl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(MLPClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model\n",
        "input_size = X_train_t.shape[1]\n",
        "hidden_size = 16\n",
        "output_size = len(iris.target_names)\n",
        "\n",
        "pt_model_classification = MLPClassifier(input_size, hidden_size, output_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(pt_model_classification.parameters(), lr=0.01)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HX-39tkXjj1_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 14: (PyTorch) Train the Classification Model"
      ],
      "metadata": {
        "id": "Z_G4WcvJjl57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = pt_model_classification(X_train_t)\n",
        "    loss = criterion(outputs, y_train_t)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrNI2uYtjnnt",
        "outputId": "eb20fa4a-25e9-4ab0-d4ff-2f5d5667cf1f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/100], Loss: 1.0417\n",
            "Epoch [10/100], Loss: 0.8817\n",
            "Epoch [20/100], Loss: 0.7931\n",
            "Epoch [30/100], Loss: 0.7436\n",
            "Epoch [40/100], Loss: 0.7116\n",
            "Epoch [50/100], Loss: 0.6828\n",
            "Epoch [60/100], Loss: 0.6528\n",
            "Epoch [70/100], Loss: 0.6279\n",
            "Epoch [80/100], Loss: 0.6091\n",
            "Epoch [90/100], Loss: 0.5976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 15: (PyTorch) Evaluate the Classification Model"
      ],
      "metadata": {
        "id": "BF9t_-Ykjt7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    predictions = pt_model_classification(X_test_t)\n",
        "    predicted_labels = torch.argmax(predictions, axis=1)\n",
        "    accuracy = (predicted_labels == y_test_t).sum().item() / y_test_t.size(0)\n",
        "\n",
        "print(f'Classification Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pRkJ9flj3DS",
        "outputId": "99658c3f-79a2-42ee-ed70-e2d4af572466"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 16: (PyTorch) Make Predictions with the Classification Model"
      ],
      "metadata": {
        "id": "GY0yhjstj60B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input = torch.tensor([[6.7, 3.1, 4.9, 1.5]])  # Example from dataset\n",
        "with torch.no_grad():\n",
        "    prediction = pt_model_classification(sample_input)\n",
        "    predicted_class = torch.argmax(prediction, axis=1).item()\n",
        "\n",
        "print(f'Predicted Class: {iris.target_names[predicted_class]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At8UV4Zfj_z8",
        "outputId": "64dbab29-ec63-41b1-d160-dd5ae159f528"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: virginica\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 17: (TensorFlow) Build the MLP Model for Classification"
      ],
      "metadata": {
        "id": "8QSJHKRJkDGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_one_hot = to_categorical(y_train, num_classes=3)\n",
        "y_test_one_hot = to_categorical(y_test, num_classes=3)\n",
        "\n",
        "# Create a new model (to avoid sharing weights)\n",
        "tf_model_classification = keras.Sequential([\n",
        "    Input(shape=(X_train.shape[1],)),  # Define input layer\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(8, activation=\"relu\"),\n",
        "    layers.Dense(3, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile with categorical crossentropy\n",
        "tf_model_classification.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "tf_model_classification.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "ImEuEZdlkHPM",
        "outputId": "c1b61287-70f4-46c0-b082-d97931a41f8d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m80\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m27\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m243\u001b[0m (972.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">243</span> (972.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m243\u001b[0m (972.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">243</span> (972.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 18: (TensorFlow) Train the Classification Model"
      ],
      "metadata": {
        "id": "TZnTxlzfkJsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history_classification = tf_model_classification.fit(\n",
        "    X_train, y_train_one_hot,\n",
        "    validation_data=(X_test, y_test_one_hot),\n",
        "    epochs=100,\n",
        "    batch_size=16,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUqY1KIDkQqR",
        "outputId": "22d6902e-5336-4a30-96fd-09f3b2804d68"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.3366 - loss: 1.0406 - val_accuracy: 0.6667 - val_loss: 0.9928\n",
            "Epoch 2/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5958 - loss: 0.9887 - val_accuracy: 0.7000 - val_loss: 0.9438\n",
            "Epoch 3/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6029 - loss: 0.9529 - val_accuracy: 0.7000 - val_loss: 0.8984\n",
            "Epoch 4/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6329 - loss: 0.8816 - val_accuracy: 0.7000 - val_loss: 0.8547\n",
            "Epoch 5/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6305 - loss: 0.8624 - val_accuracy: 0.7000 - val_loss: 0.8150\n",
            "Epoch 6/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6931 - loss: 0.7941 - val_accuracy: 0.7333 - val_loss: 0.7770\n",
            "Epoch 7/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6490 - loss: 0.7717 - val_accuracy: 0.7333 - val_loss: 0.7421\n",
            "Epoch 8/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6589 - loss: 0.7595 - val_accuracy: 0.7667 - val_loss: 0.7100\n",
            "Epoch 9/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6703 - loss: 0.7424 - val_accuracy: 0.7667 - val_loss: 0.6801\n",
            "Epoch 10/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6904 - loss: 0.6970 - val_accuracy: 0.7667 - val_loss: 0.6516\n",
            "Epoch 11/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6825 - loss: 0.6858 - val_accuracy: 0.8000 - val_loss: 0.6251\n",
            "Epoch 12/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7440 - loss: 0.6393 - val_accuracy: 0.8000 - val_loss: 0.5996\n",
            "Epoch 13/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6832 - loss: 0.6581 - val_accuracy: 0.8000 - val_loss: 0.5768\n",
            "Epoch 14/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7748 - loss: 0.5466 - val_accuracy: 0.8000 - val_loss: 0.5547\n",
            "Epoch 15/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7595 - loss: 0.5931 - val_accuracy: 0.8000 - val_loss: 0.5351\n",
            "Epoch 16/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8038 - loss: 0.5277 - val_accuracy: 0.8000 - val_loss: 0.5174\n",
            "Epoch 17/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7880 - loss: 0.5227 - val_accuracy: 0.8000 - val_loss: 0.5011\n",
            "Epoch 18/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7179 - loss: 0.5522 - val_accuracy: 0.8000 - val_loss: 0.4870\n",
            "Epoch 19/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7497 - loss: 0.5270 - val_accuracy: 0.8000 - val_loss: 0.4738\n",
            "Epoch 20/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7908 - loss: 0.5019 - val_accuracy: 0.8000 - val_loss: 0.4617\n",
            "Epoch 21/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7795 - loss: 0.5052 - val_accuracy: 0.8000 - val_loss: 0.4507\n",
            "Epoch 22/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7844 - loss: 0.5131 - val_accuracy: 0.8000 - val_loss: 0.4400\n",
            "Epoch 23/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7630 - loss: 0.5035 - val_accuracy: 0.8000 - val_loss: 0.4305\n",
            "Epoch 24/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8033 - loss: 0.4849 - val_accuracy: 0.8000 - val_loss: 0.4211\n",
            "Epoch 25/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7963 - loss: 0.4727 - val_accuracy: 0.8000 - val_loss: 0.4123\n",
            "Epoch 26/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8621 - loss: 0.3926 - val_accuracy: 0.8000 - val_loss: 0.4037\n",
            "Epoch 27/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8289 - loss: 0.4224 - val_accuracy: 0.8333 - val_loss: 0.3958\n",
            "Epoch 28/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8261 - loss: 0.4253 - val_accuracy: 0.8333 - val_loss: 0.3873\n",
            "Epoch 29/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8498 - loss: 0.4055 - val_accuracy: 0.8333 - val_loss: 0.3787\n",
            "Epoch 30/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8209 - loss: 0.4382 - val_accuracy: 0.8333 - val_loss: 0.3707\n",
            "Epoch 31/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8466 - loss: 0.4202 - val_accuracy: 0.8667 - val_loss: 0.3622\n",
            "Epoch 32/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8219 - loss: 0.3970 - val_accuracy: 0.8667 - val_loss: 0.3542\n",
            "Epoch 33/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8406 - loss: 0.3980 - val_accuracy: 0.8667 - val_loss: 0.3468\n",
            "Epoch 34/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8535 - loss: 0.3776 - val_accuracy: 0.8667 - val_loss: 0.3390\n",
            "Epoch 35/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8359 - loss: 0.4105 - val_accuracy: 0.8667 - val_loss: 0.3309\n",
            "Epoch 36/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8389 - loss: 0.3952 - val_accuracy: 0.8667 - val_loss: 0.3237\n",
            "Epoch 37/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8442 - loss: 0.3938 - val_accuracy: 0.9000 - val_loss: 0.3159\n",
            "Epoch 38/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8948 - loss: 0.3435 - val_accuracy: 0.9000 - val_loss: 0.3094\n",
            "Epoch 39/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8298 - loss: 0.3687 - val_accuracy: 0.9000 - val_loss: 0.3014\n",
            "Epoch 40/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8497 - loss: 0.3247 - val_accuracy: 0.9000 - val_loss: 0.2942\n",
            "Epoch 41/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8918 - loss: 0.3200 - val_accuracy: 0.9000 - val_loss: 0.2862\n",
            "Epoch 42/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8645 - loss: 0.3347 - val_accuracy: 0.9000 - val_loss: 0.2782\n",
            "Epoch 43/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8694 - loss: 0.3153 - val_accuracy: 0.9000 - val_loss: 0.2705\n",
            "Epoch 44/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8944 - loss: 0.3239 - val_accuracy: 0.9333 - val_loss: 0.2624\n",
            "Epoch 45/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8800 - loss: 0.3317 - val_accuracy: 0.9333 - val_loss: 0.2563\n",
            "Epoch 46/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9001 - loss: 0.2786 - val_accuracy: 0.9333 - val_loss: 0.2498\n",
            "Epoch 47/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8967 - loss: 0.2617 - val_accuracy: 0.9333 - val_loss: 0.2434\n",
            "Epoch 48/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9148 - loss: 0.2633 - val_accuracy: 0.9333 - val_loss: 0.2357\n",
            "Epoch 49/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8797 - loss: 0.3034 - val_accuracy: 0.9333 - val_loss: 0.2286\n",
            "Epoch 50/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9170 - loss: 0.2731 - val_accuracy: 0.9333 - val_loss: 0.2224\n",
            "Epoch 51/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9251 - loss: 0.2415 - val_accuracy: 0.9333 - val_loss: 0.2166\n",
            "Epoch 52/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9192 - loss: 0.2488 - val_accuracy: 0.9333 - val_loss: 0.2114\n",
            "Epoch 53/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9221 - loss: 0.2453 - val_accuracy: 0.9667 - val_loss: 0.2045\n",
            "Epoch 54/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9412 - loss: 0.2149 - val_accuracy: 0.9667 - val_loss: 0.1981\n",
            "Epoch 55/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9353 - loss: 0.2455 - val_accuracy: 0.9667 - val_loss: 0.1919\n",
            "Epoch 56/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9270 - loss: 0.2360 - val_accuracy: 0.9667 - val_loss: 0.1862\n",
            "Epoch 57/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9296 - loss: 0.2325 - val_accuracy: 0.9667 - val_loss: 0.1804\n",
            "Epoch 58/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9417 - loss: 0.2251 - val_accuracy: 0.9667 - val_loss: 0.1751\n",
            "Epoch 59/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9053 - loss: 0.2260 - val_accuracy: 0.9667 - val_loss: 0.1713\n",
            "Epoch 60/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9455 - loss: 0.2061 - val_accuracy: 0.9667 - val_loss: 0.1675\n",
            "Epoch 61/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9300 - loss: 0.2189 - val_accuracy: 0.9667 - val_loss: 0.1632\n",
            "Epoch 62/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9333 - loss: 0.2061 - val_accuracy: 0.9667 - val_loss: 0.1592\n",
            "Epoch 63/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9400 - loss: 0.1887 - val_accuracy: 0.9667 - val_loss: 0.1569\n",
            "Epoch 64/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9461 - loss: 0.1921 - val_accuracy: 0.9667 - val_loss: 0.1525\n",
            "Epoch 65/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9692 - loss: 0.1685 - val_accuracy: 0.9667 - val_loss: 0.1476\n",
            "Epoch 66/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9655 - loss: 0.1731 - val_accuracy: 0.9667 - val_loss: 0.1443\n",
            "Epoch 67/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9434 - loss: 0.1926 - val_accuracy: 0.9667 - val_loss: 0.1412\n",
            "Epoch 68/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9340 - loss: 0.1850 - val_accuracy: 0.9667 - val_loss: 0.1384\n",
            "Epoch 69/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9321 - loss: 0.2105 - val_accuracy: 0.9667 - val_loss: 0.1346\n",
            "Epoch 70/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9693 - loss: 0.1731 - val_accuracy: 1.0000 - val_loss: 0.1315\n",
            "Epoch 71/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9471 - loss: 0.1604 - val_accuracy: 1.0000 - val_loss: 0.1296\n",
            "Epoch 72/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9513 - loss: 0.1636 - val_accuracy: 1.0000 - val_loss: 0.1271\n",
            "Epoch 73/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9334 - loss: 0.1733 - val_accuracy: 1.0000 - val_loss: 0.1236\n",
            "Epoch 74/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9614 - loss: 0.1490 - val_accuracy: 1.0000 - val_loss: 0.1208\n",
            "Epoch 75/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9550 - loss: 0.1567 - val_accuracy: 1.0000 - val_loss: 0.1169\n",
            "Epoch 76/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9578 - loss: 0.1359 - val_accuracy: 1.0000 - val_loss: 0.1149\n",
            "Epoch 77/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9812 - loss: 0.1210 - val_accuracy: 1.0000 - val_loss: 0.1115\n",
            "Epoch 78/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9644 - loss: 0.1455 - val_accuracy: 1.0000 - val_loss: 0.1083\n",
            "Epoch 79/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9636 - loss: 0.1333 - val_accuracy: 1.0000 - val_loss: 0.1069\n",
            "Epoch 80/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9550 - loss: 0.1338 - val_accuracy: 1.0000 - val_loss: 0.1063\n",
            "Epoch 81/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9232 - loss: 0.1531 - val_accuracy: 1.0000 - val_loss: 0.1041\n",
            "Epoch 82/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9577 - loss: 0.1416 - val_accuracy: 1.0000 - val_loss: 0.1031\n",
            "Epoch 83/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9681 - loss: 0.1299 - val_accuracy: 1.0000 - val_loss: 0.1019\n",
            "Epoch 84/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9799 - loss: 0.1057 - val_accuracy: 1.0000 - val_loss: 0.0990\n",
            "Epoch 85/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9751 - loss: 0.1059 - val_accuracy: 1.0000 - val_loss: 0.0967\n",
            "Epoch 86/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9436 - loss: 0.1413 - val_accuracy: 1.0000 - val_loss: 0.0960\n",
            "Epoch 87/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9687 - loss: 0.1340 - val_accuracy: 1.0000 - val_loss: 0.0957\n",
            "Epoch 88/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9475 - loss: 0.1362 - val_accuracy: 1.0000 - val_loss: 0.0946\n",
            "Epoch 89/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9519 - loss: 0.1517 - val_accuracy: 1.0000 - val_loss: 0.0917\n",
            "Epoch 90/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9581 - loss: 0.1168 - val_accuracy: 1.0000 - val_loss: 0.0885\n",
            "Epoch 91/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9800 - loss: 0.1104 - val_accuracy: 1.0000 - val_loss: 0.0872\n",
            "Epoch 92/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9600 - loss: 0.1151 - val_accuracy: 1.0000 - val_loss: 0.0861\n",
            "Epoch 93/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9420 - loss: 0.1323 - val_accuracy: 1.0000 - val_loss: 0.0851\n",
            "Epoch 94/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9734 - loss: 0.1111 - val_accuracy: 1.0000 - val_loss: 0.0834\n",
            "Epoch 95/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9563 - loss: 0.1213 - val_accuracy: 1.0000 - val_loss: 0.0812\n",
            "Epoch 96/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9511 - loss: 0.1217 - val_accuracy: 1.0000 - val_loss: 0.0819\n",
            "Epoch 97/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9677 - loss: 0.0900 - val_accuracy: 1.0000 - val_loss: 0.0806\n",
            "Epoch 98/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9553 - loss: 0.0980 - val_accuracy: 1.0000 - val_loss: 0.0796\n",
            "Epoch 99/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9676 - loss: 0.0959 - val_accuracy: 1.0000 - val_loss: 0.0777\n",
            "Epoch 100/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9384 - loss: 0.1233 - val_accuracy: 1.0000 - val_loss: 0.0761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 19: (TensorFlow) Evaluate the Classification Model"
      ],
      "metadata": {
        "id": "55bD72DDkTZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "# Use one-hot encoded labels for evaluation\n",
        "loss, accuracy = tf_model_classification.evaluate(X_test, y_test_one_hot)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Gq3bLY5kZJ-",
        "outputId": "faa04842-5604-42cf-d38e-bcec824a15a5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0761\n",
            "Test Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 20: Make Predictions with the Classification Model"
      ],
      "metadata": {
        "id": "3LtG1TMOkbye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample input for prediction\n",
        "sample_input = np.array([[6.7, 3.1, 4.9, 1.5]])  # Example from Iris dataset\n",
        "\n",
        "# Make prediction\n",
        "tf_model_classification_prediction = tf_model_classification.predict(sample_input)\n",
        "tf_predicted_class = np.argmax(tf_model_classification_prediction, axis=1)[0]\n",
        "\n",
        "# Output predicted class\n",
        "print(f\"Predicted Class: {iris.target_names[predicted_class]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_xw_4XskcJS",
        "outputId": "75cdae91-9af7-4a89-e58e-a0163753127e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
            "Predicted Class: virginica\n"
          ]
        }
      ]
    }
  ]
}